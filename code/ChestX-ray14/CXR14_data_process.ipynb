{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41eb2a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import csv \n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "073ad3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
      "0       00000001_000.png            Cardiomegaly            0           1   \n",
      "1       00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
      "2       00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
      "3       00000002_000.png              No Finding            0           2   \n",
      "4       00000003_001.png                  Hernia            0           3   \n",
      "...                  ...                     ...          ...         ...   \n",
      "112115  00030801_001.png          Mass|Pneumonia            1       30801   \n",
      "112116  00030802_000.png              No Finding            0       30802   \n",
      "112117  00030803_000.png              No Finding            0       30803   \n",
      "112118  00030804_000.png              No Finding            0       30804   \n",
      "112119  00030805_000.png              No Finding            0       30805   \n",
      "\n",
      "        Patient Age Patient Gender View Position  OriginalImage[Width  \\\n",
      "0                57              M            PA                 2682   \n",
      "1                58              M            PA                 2894   \n",
      "2                58              M            PA                 2500   \n",
      "3                80              M            PA                 2500   \n",
      "4                74              F            PA                 2500   \n",
      "...             ...            ...           ...                  ...   \n",
      "112115           38              M            PA                 2048   \n",
      "112116           28              M            PA                 2048   \n",
      "112117           42              F            PA                 2048   \n",
      "112118           29              F            PA                 2048   \n",
      "112119           26              M            PA                 2048   \n",
      "\n",
      "        Height]  OriginalImagePixelSpacing[x     y]  \n",
      "0          2749                        0.143  0.143  \n",
      "1          2729                        0.143  0.143  \n",
      "2          2048                        0.168  0.168  \n",
      "3          2048                        0.171  0.171  \n",
      "4          2048                        0.168  0.168  \n",
      "...         ...                          ...    ...  \n",
      "112115     2500                        0.168  0.168  \n",
      "112116     2500                        0.168  0.168  \n",
      "112117     2500                        0.168  0.168  \n",
      "112118     2500                        0.168  0.168  \n",
      "112119     2500                        0.171  0.171  \n",
      "\n",
      "[112120 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "names = []\n",
    "target = []\n",
    "\n",
    "data_sheet = pd.read_csv(\"CXR14/CXR8/Data_Entry_2017_v2020.csv\")\n",
    "\n",
    "print(data_sheet)\n",
    "\n",
    "N = data_sheet.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread \n",
    "import PIL \n",
    "from PIL import Image \n",
    "from torchvision import transforms \n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.5.0', 'densenet121', pretrained=True).to(device)\n",
    "# or any of these variants\n",
    "#model = torch.hub.load('pytorch/vision:v0.5.0', 'densenet169', pretrained=True).to(device)\n",
    "#model = torch.hub.load('pytorch/vision:v0.5.0', 'densenet201', pretrained=True).to(device)\n",
    "#model = torch.hub.load('pytorch/vision:v0.5.0', 'densenet161', pretrained=True).to(device)\n",
    "model.eval()\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def run_through_denseNetPyTorch(img, densenet_model, device):\n",
    "    \n",
    "    img = torch.unsqueeze(img.to(device), 0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = densenet_model.features( img )\n",
    "        f_relu = torch.nn.functional.relu( features )\n",
    "        pool = torch.nn.functional.adaptive_avg_pool2d( f_relu, (1,1) )\n",
    "\n",
    "        y_st = pool.cpu().numpy().reshape(-1)\n",
    "    \n",
    "    return y_st\n",
    "\n",
    "\n",
    "X_train_0 = [] \n",
    "y_train_0 = []\n",
    "\n",
    "fnames = data_sheet['Image Index']\n",
    "labels = data_sheet['View Position']\n",
    "\n",
    "for i in range(N):\n",
    "    if i%10000 == 0:\n",
    "        print('Completed ', i, ' of ', N)\n",
    "    \n",
    "    \n",
    "    filename = 'CXR14/CXR8/images/extracted/'+fnames[i]\n",
    "    img = imread(filename, as_gray=False, pilmode=\"RGB\") \n",
    "    \n",
    "    img = Image.fromarray(img)\n",
    "    img = PIL.ImageOps.equalize(img)\n",
    "    img = preprocess(img)\n",
    "    \n",
    "    X_train_0.append(run_through_denseNetPyTorch(img=img, densenet_model=model, device=device))\n",
    "    if labels[i] == 'PA':\n",
    "        y_train_0.append(0)\n",
    "    elif labels[i] == 'AP':\n",
    "        y_train_0.append(1)\n",
    "    else:\n",
    "        print('View Position not PA or AP. Instead found ', labels[i], 'at index', i)\n",
    "        print(wronginfor)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ead7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112120, 1024)\n",
      "67310\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_0 = np.array(X_train_0)\n",
    "y_train_0 = np.array(y_train_0)\n",
    "fnames = np.array(fnames)\n",
    "print(X_train_0.shape)\n",
    "print(np.sum(y_train_0==0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ad055f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"CXR14_DenseNet.npy\", 'wb') as f:\n",
    "    np.save(f,X_train_0)\n",
    "    np.save(f,y_train_0)\n",
    "    np.save(f,fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fe5655",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
