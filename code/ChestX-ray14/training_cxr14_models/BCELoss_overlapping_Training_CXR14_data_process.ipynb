{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41eb2a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "import csv \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae118ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_names = np.array(['Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', \n",
    "                 'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', 'Consolidation', 'Edema',\n",
    "                'Emphysema', 'Fibrosis', 'Pleural_Thickening', 'Hernia', 'No Finding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073ad3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Image Index          Finding Labels  Follow-up #  Patient ID  \\\n",
      "0       00000001_000.png            Cardiomegaly            0           1   \n",
      "1       00000001_001.png  Cardiomegaly|Emphysema            1           1   \n",
      "2       00000001_002.png   Cardiomegaly|Effusion            2           1   \n",
      "3       00000002_000.png              No Finding            0           2   \n",
      "4       00000003_001.png                  Hernia            0           3   \n",
      "...                  ...                     ...          ...         ...   \n",
      "112115  00030801_001.png          Mass|Pneumonia            1       30801   \n",
      "112116  00030802_000.png              No Finding            0       30802   \n",
      "112117  00030803_000.png              No Finding            0       30803   \n",
      "112118  00030804_000.png              No Finding            0       30804   \n",
      "112119  00030805_000.png              No Finding            0       30805   \n",
      "\n",
      "        Patient Age Patient Gender View Position  OriginalImage[Width  \\\n",
      "0                57              M            PA                 2682   \n",
      "1                58              M            PA                 2894   \n",
      "2                58              M            PA                 2500   \n",
      "3                80              M            PA                 2500   \n",
      "4                74              F            PA                 2500   \n",
      "...             ...            ...           ...                  ...   \n",
      "112115           38              M            PA                 2048   \n",
      "112116           28              M            PA                 2048   \n",
      "112117           42              F            PA                 2048   \n",
      "112118           29              F            PA                 2048   \n",
      "112119           26              M            PA                 2048   \n",
      "\n",
      "        Height]  OriginalImagePixelSpacing[x     y]  \n",
      "0          2749                        0.143  0.143  \n",
      "1          2729                        0.143  0.143  \n",
      "2          2048                        0.168  0.168  \n",
      "3          2048                        0.171  0.171  \n",
      "4          2048                        0.168  0.168  \n",
      "...         ...                          ...    ...  \n",
      "112115     2500                        0.168  0.168  \n",
      "112116     2500                        0.168  0.168  \n",
      "112117     2500                        0.168  0.168  \n",
      "112118     2500                        0.168  0.168  \n",
      "112119     2500                        0.171  0.171  \n",
      "\n",
      "[112120 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "names = []\n",
    "target = []\n",
    "\n",
    "data_sheet = pd.read_csv(\"/home/user/Chest_X_Ray_Data/CXR14/CXR8/Data_Entry_2017_v2020.csv\")\n",
    "\n",
    "print(data_sheet)\n",
    "\n",
    "N = data_sheet.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f69c89fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Atelectasis' 'Cardiomegaly' 'Consolidation' 'Edema' 'Effusion'\n",
      " 'Emphysema' 'Fibrosis' 'Hernia' 'Infiltration' 'Mass' 'No Finding'\n",
      " 'Nodule' 'Pleural_Thickening' 'Pneumonia' 'Pneumothorax']\n"
     ]
    }
   ],
   "source": [
    "individual_lebels = []\n",
    "\n",
    "all_labels = data_sheet['Finding Labels']\n",
    "\n",
    "for i in range(N):\n",
    "    label = all_labels[i] \n",
    "    if '|' in label:\n",
    "        pass\n",
    "    else:\n",
    "        individual_lebels.append(label)\n",
    "\n",
    "print(np.unique(individual_lebels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5679b0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "g = np.where(np.array(['Atelectasis', 'Cardiomegaly', 'Effusion'])=='Cardiomegaly')[0]\n",
    "print(g)\n",
    "print(len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9ead7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Atelectasis': [], 'Cardiomegaly': [], 'Effusion': [], 'Infiltration': [], 'Mass': [], 'Nodule': [], 'Pneumonia': [], 'Pneumothorax': [], 'Consolidation': [], 'Edema': [], 'Emphysema': [], 'Fibrosis': [], 'Pleural_Thickening': [], 'Hernia': [], 'No Finding': []}\n"
     ]
    }
   ],
   "source": [
    "filenames = {}\n",
    "for disease in disease_names:\n",
    "    filenames[disease] = []\n",
    "    \n",
    "print(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ad055f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed  0  of  112120\n",
      "Completed  10000  of  112120\n",
      "Completed  20000  of  112120\n",
      "Completed  30000  of  112120\n",
      "Completed  40000  of  112120\n",
      "Completed  50000  of  112120\n",
      "Completed  60000  of  112120\n",
      "Completed  70000  of  112120\n",
      "Completed  80000  of  112120\n",
      "Completed  90000  of  112120\n",
      "Completed  100000  of  112120\n",
      "Completed  110000  of  112120\n"
     ]
    }
   ],
   "source": [
    "all_files = data_sheet['Image Index']\n",
    "all_labels = data_sheet['Finding Labels']\n",
    "\n",
    "full_labels = np.zeros((N,len(disease_names)),dtype=np.float32)\n",
    "\n",
    "for i in range(N):\n",
    "    if i%10000 == 0:\n",
    "        print('Completed ', i, ' of ', N)\n",
    "    label = all_labels[i]\n",
    "    for j in range(len(disease_names)):\n",
    "        disease = disease_names[j]\n",
    "        \n",
    "        if disease in label:\n",
    "            full_labels[i,j] = 1.0\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fe5655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cac3201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageio import imread \n",
    "import PIL \n",
    "from PIL import Image \n",
    "from torchvision import transforms \n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "device = torch.device(\"cuda:1\") # if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    #transforms.CenterCrop(224),\n",
    "    #transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "#all_files = data_sheet['Image Index']\n",
    "#full_labels\n",
    "\n",
    "loaded_images= []\n",
    "\n",
    "for i in range(len(all_files)):\n",
    "\n",
    "    file_to_load = '/home/user/Chest_X_Ray_Data/CXR14/CXR8/images/extracted/'+all_files[i]\n",
    "    img = imread(file_to_load, as_gray=False, pilmode=\"RGB\") \n",
    "    img = Image.fromarray(img)\n",
    "    img = PIL.ImageOps.equalize(img)\n",
    "    img = preprocess(img)\n",
    "    loaded_images.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f55eef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112120\n",
      "[<PIL.Image.Image image mode=RGB size=256x256 at 0x7F45FF557A90>, <PIL.Image.Image image mode=RGB size=256x256 at 0x7F45FF5579E8>]\n"
     ]
    }
   ],
   "source": [
    "print(len(loaded_images))\n",
    "print(loaded_images[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f370150f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30, 3, 224, 224])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:1', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "augments = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "def sample_images(images,full_labels, device, n_sample=5):\n",
    "    N = len(images)\n",
    "    chs = np.random.choice(N,n_sample)\n",
    "    augmented_images = []\n",
    "    for idx in chs:\n",
    "        img = augments(images[idx])\n",
    "        augmented_images.append(img)\n",
    "    \n",
    "    labels = torch.as_tensor(full_labels[chs]).to(device)\n",
    "    augmented_images = torch.stack(augmented_images).to(device)\n",
    "    \n",
    "    return augmented_images, labels\n",
    "\n",
    "G, label = sample_images(loaded_images,full_labels,device,n_sample=30)\n",
    "print(G.size())\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc50a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "model = torch.hub.load('pytorch/vision:v0.5.0', 'densenet121', pretrained=False)\n",
    "model.classifier = nn.Linear(1024, 15)\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2614be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.211\n",
      "[1,  4000] loss: 0.205\n",
      "[1,  6000] loss: 0.203\n",
      "[1,  8000] loss: 0.200\n",
      "[1, 10000] loss: 0.198\n",
      "[2,  2000] loss: 0.196\n",
      "[2,  4000] loss: 0.195\n",
      "[2,  6000] loss: 0.193\n",
      "[2,  8000] loss: 0.192\n",
      "[2, 10000] loss: 0.191\n",
      "[3,  2000] loss: 0.190\n",
      "[3,  4000] loss: 0.189\n",
      "[3,  6000] loss: 0.188\n",
      "[3,  8000] loss: 0.186\n",
      "[3, 10000] loss: 0.187\n",
      "[4,  2000] loss: 0.185\n",
      "[4,  4000] loss: 0.185\n",
      "[4,  6000] loss: 0.185\n",
      "[4,  8000] loss: 0.183\n",
      "[4, 10000] loss: 0.183\n",
      "[5,  2000] loss: 0.183\n",
      "[5,  4000] loss: 0.182\n",
      "[5,  6000] loss: 0.182\n",
      "[5,  8000] loss: 0.181\n",
      "[5, 10000] loss: 0.181\n",
      "[6,  2000] loss: 0.178\n",
      "[6,  4000] loss: 0.179\n",
      "[6,  6000] loss: 0.178\n",
      "[6,  8000] loss: 0.178\n",
      "[6, 10000] loss: 0.178\n",
      "[7,  2000] loss: 0.179\n",
      "[7,  4000] loss: 0.178\n",
      "[7,  6000] loss: 0.177\n",
      "[7,  8000] loss: 0.176\n",
      "[7, 10000] loss: 0.177\n",
      "[8,  2000] loss: 0.177\n",
      "[8,  4000] loss: 0.176\n",
      "[8,  6000] loss: 0.175\n",
      "[8,  8000] loss: 0.175\n",
      "[8, 10000] loss: 0.172\n",
      "[9,  2000] loss: 0.172\n",
      "[9,  4000] loss: 0.174\n",
      "[9,  6000] loss: 0.174\n",
      "[9,  8000] loss: 0.172\n",
      "[9, 10000] loss: 0.172\n",
      "[10,  2000] loss: 0.173\n",
      "[10,  4000] loss: 0.172\n",
      "[10,  6000] loss: 0.171\n",
      "[10,  8000] loss: 0.170\n",
      "[10, 10000] loss: 0.170\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i in range(10000):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = sample_images(loaded_images,full_labels,device,n_sample=30)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = m(model(inputs))\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "725aa4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'saved_model/cxr14_overlapping_labels_bceloss_densenet_121.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bdec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.hub.load('pytorch/vision:v0.5.0', 'densenet121', pretrained=False)\n",
    "model2.classifier = nn.Linear(1024, 15)\n",
    "\n",
    "model2.load_state_dict(torch.load('saved_model/cxr14_overlapping_labels_bceloss_densenet_121.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97594ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
